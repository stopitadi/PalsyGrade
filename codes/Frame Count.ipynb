{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a84001c-38ed-42dc-b7ca-b0fee54aaa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames: 1200\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def count_frames(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video file was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the total number of frames\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "# Example usage\n",
    "video_path = r\"C:\\Users\\hp\\Desktop\\detection of the bels palsy\\mediapipe\\CAAI_dataset\\bels plasy video datadset\\bels plasy videos dataset\\belsplasy\\1.mp4\"\n",
    "total_frames = count_frames(video_path)\n",
    "print(f'Total number of frames: {total_frames}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c067bb30-9ecf-4fd8-9432-95633ff6df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/120\n",
      "Processing frame 2/120\n",
      "Processing frame 3/120\n",
      "Processing frame 4/120\n",
      "Processing frame 5/120\n",
      "Processing frame 6/120\n",
      "Processing frame 7/120\n",
      "Processing frame 8/120\n",
      "Processing frame 9/120\n",
      "Processing frame 10/120\n",
      "Processing frame 11/120\n",
      "Processing frame 12/120\n",
      "Processing frame 13/120\n",
      "Processing frame 14/120\n",
      "Processing frame 15/120\n",
      "Processing frame 16/120\n",
      "Processing frame 17/120\n",
      "Processing frame 18/120\n",
      "Processing frame 19/120\n",
      "Processing frame 20/120\n",
      "Processing frame 21/120\n",
      "Processing frame 22/120\n",
      "Processing frame 23/120\n",
      "Processing frame 24/120\n",
      "Processing frame 25/120\n",
      "Processing frame 26/120\n",
      "Processing frame 27/120\n",
      "Processing frame 28/120\n",
      "Processing frame 29/120\n",
      "Processing frame 30/120\n",
      "Processing frame 31/120\n",
      "Processing frame 32/120\n",
      "Processing frame 33/120\n",
      "Processing frame 34/120\n",
      "Processing frame 35/120\n",
      "Processing frame 36/120\n",
      "Processing frame 37/120\n",
      "Processing frame 38/120\n",
      "Processing frame 39/120\n",
      "Processing frame 40/120\n",
      "Processing frame 41/120\n",
      "Processing frame 42/120\n",
      "Processing frame 43/120\n",
      "Processing frame 44/120\n",
      "Processing frame 45/120\n",
      "Processing frame 46/120\n",
      "Processing frame 47/120\n",
      "Processing frame 48/120\n",
      "Processing frame 49/120\n",
      "Processing frame 50/120\n",
      "Processing frame 51/120\n",
      "Processing frame 52/120\n",
      "Processing frame 53/120\n",
      "Processing frame 54/120\n",
      "Processing frame 55/120\n",
      "Processing frame 56/120\n",
      "Processing frame 57/120\n",
      "Processing frame 58/120\n",
      "Processing frame 59/120\n",
      "Processing frame 60/120\n",
      "Processing frame 61/120\n",
      "Processing frame 62/120\n",
      "Processing frame 63/120\n",
      "Processing frame 64/120\n",
      "Processing frame 65/120\n",
      "Processing frame 66/120\n",
      "Processing frame 67/120\n",
      "Processing frame 68/120\n",
      "Processing frame 69/120\n",
      "Processing frame 70/120\n",
      "Processing frame 71/120\n",
      "Processing frame 72/120\n",
      "Processing frame 73/120\n",
      "Processing frame 74/120\n",
      "Processing frame 75/120\n",
      "Processing frame 76/120\n",
      "Processing frame 77/120\n",
      "Processing frame 78/120\n",
      "Processing frame 79/120\n",
      "Processing frame 80/120\n",
      "Processing frame 81/120\n",
      "Processing frame 82/120\n",
      "Processing frame 83/120\n",
      "Processing frame 84/120\n",
      "Processing frame 85/120\n",
      "Processing frame 86/120\n",
      "Processing frame 87/120\n",
      "Processing frame 88/120\n",
      "Processing frame 89/120\n",
      "Processing frame 90/120\n",
      "Processing frame 91/120\n",
      "Processing frame 92/120\n",
      "Processing frame 93/120\n",
      "Processing frame 94/120\n",
      "Processing frame 95/120\n",
      "Processing frame 96/120\n",
      "Processing frame 97/120\n",
      "Processing frame 98/120\n",
      "Processing frame 99/120\n",
      "Processing frame 100/120\n",
      "Processing frame 101/120\n",
      "Processing frame 102/120\n",
      "Processing frame 103/120\n",
      "Processing frame 104/120\n",
      "Processing frame 105/120\n",
      "Processing frame 106/120\n",
      "Processing frame 107/120\n",
      "Processing frame 108/120\n",
      "Processing frame 109/120\n",
      "Processing frame 110/120\n",
      "Processing frame 111/120\n",
      "Processing frame 112/120\n",
      "Processing frame 113/120\n",
      "Processing frame 114/120\n",
      "Processing frame 115/120\n",
      "Processing frame 116/120\n",
      "Processing frame 117/120\n",
      "Processing frame 118/120\n",
      "Processing frame 119/120\n",
      "Processing frame 120/120\n",
      "Video cropped and saved to C:\\Users\\hp\\Desktop\\detection of the bels palsy\\mediapipe\\CAAI_dataset\\bels plasy video datadset\\bels plasy videos dataset\\belChec\\cropped_41.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_video_to_5_seconds(video_path, output_video_path, duration_seconds=5):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video file was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "    \n",
    "    # Get the video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate the number of frames to capture\n",
    "    num_frames = int(fps * duration_seconds)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' or 'MJPG' for other formats\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened() and frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame or video ended early.\")\n",
    "            break\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        print(f\"Processing frame {frame_count}/{num_frames}\")\n",
    "    \n",
    "    # Release the video objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Video cropped and saved to {output_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = r\"C:\\Users\\hp\\Desktop\\detection of the bels palsy\\mediapipe\\CAAI_dataset\\bels plasy video datadset\\bels plasy videos dataset\\belsplasy\\41.mp4\"  # Update with your input video file path\n",
    "output_video_path = r\"C:\\Users\\hp\\Desktop\\detection of the bels palsy\\mediapipe\\CAAI_dataset\\bels plasy video datadset\\bels plasy videos dataset\\belChec\\cropped_41.mp4\"  # Update with your output video file path\n",
    "\n",
    "crop_video_to_5_seconds(video_path, output_video_path, duration_seconds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38e459-9771-46f7-8f8a-12cdcadc74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_video_to_5_seconds(video_path, output_video_path, duration_seconds=5):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video file was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "    \n",
    "    # Get the video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate the number of frames to capture\n",
    "    num_frames = int(fps * duration_seconds)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' or 'MJPG' for other formats\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened() and frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame or video ended early.\")\n",
    "            break\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        print(f\"Processing frame {frame_count}/{num_frames}\")\n",
    "    \n",
    "    # Release the video objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Video cropped and saved to {output_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = r\"path_to_your_input_video.mp4\"  # Update with your input video file path\n",
    "output_video_path = r\"path_to_your_output_video.mp4\"  # Update with your output video file path\n",
    "\n",
    "crop_video_to_5_seconds(video_path, output_video_path, duration_seconds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b194c0-6e7b-42e9-b777-3f7d6a5f0485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
